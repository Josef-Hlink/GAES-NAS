{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we run the configurations we have selected based on the results of our `experiment` notebook.\n",
    "The main difference here is that we now attach the an `IOH` logger to the problem object so we can export and visualize the results of these final runs in IOanalyzer.\n",
    "After the experiments have been done, we also visualize the results with some learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nasbench.api import NASBench\n",
    "\n",
    "from main import init_ipynb\n",
    "from utils import get_directories, ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = get_directories(os.path.join(os.path.abspath(''), 'final.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NASBench(DIRS['data'] + 'nasbench_only108.tfrecord', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = dict(budget=5000, verbose=0, repetitions=20, log=True, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'GA_fin'\n",
    "DIRS['csv_exp'] = DIRS['csv'] + exp_id + os.sep\n",
    "if not os.path.exists(DIRS['csv_exp']):\n",
    "    os.mkdir(DIRS['csv_exp'])\n",
    "\n",
    "for n, p in DIRS.items():\n",
    "    print(f'{n}: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_GA = dict(optimizer='GA', population_size=100, recombination='u', mutation='u', xp=1, mut_b=1)\n",
    "default_args_GA = default_args.copy()\n",
    "default_args_GA.update(constants_GA)\n",
    "\n",
    "#    lm, mu, sel , mut_r\n",
    "configs_GA = [\n",
    "    (80, 20, 'ts', 0.04),\n",
    "    (80, 20, 'rk', 0.01),\n",
    "    (90, 10, 'ts', 0.04),\n",
    "    (90, 10, 'rk', 0.01)\n",
    "]\n",
    "\n",
    "progress = ProgressBar(4, exp_id)\n",
    "for i, (lambda_, mu_, selection, mut_r) in enumerate(configs_GA):\n",
    "    # set the variable arguments\n",
    "    args = default_args_GA.copy()\n",
    "    args['lambda_'] = lambda_\n",
    "    args['mu_'] = mu_\n",
    "    args['selection'] = selection\n",
    "    args['mut_r'] = mut_r\n",
    "    run_id = f'GA_P100_M{mu_}_L{lambda_}_SEL{selection}_RECu_MUTu-{mut_r}'\n",
    "    args['run_id'] = run_id\n",
    "\n",
    "    # run the experiment\n",
    "    init_ipynb(NB, args, save_to=DIRS['csv_exp'])\n",
    "    progress(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evolution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'ES_fin'\n",
    "DIRS['csv_exp'] = DIRS['csv'] + exp_id + os.sep\n",
    "if not os.path.exists(DIRS['csv_exp']):\n",
    "    os.mkdir(DIRS['csv_exp'])\n",
    "\n",
    "for n, p in DIRS.items():\n",
    "    print(f'{n}: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_ES = dict(optimizer='ES', population_size=100, tau_=0.2, individual_sigmas=True, chunk_size=3)\n",
    "default_args_ES = default_args.copy()\n",
    "default_args_ES.update(constants_ES)\n",
    "\n",
    "#    lm, mu, sig, rec\n",
    "configs_ES = [\n",
    "    (80, 20, 0.5, 'd'),\n",
    "    (80, 20, 0.1, 'dg'),\n",
    "    (90, 10, 0.5, 'd'),\n",
    "    (90, 10, 0.1, 'dg')\n",
    "]\n",
    "\n",
    "progress = ProgressBar(4, exp_id)\n",
    "for i, (lambda_, mu_, sigma_, recombination) in enumerate(configs_ES):\n",
    "    # set the variable arguments\n",
    "    args = default_args_ES.copy()\n",
    "    args['lambda_'] = lambda_\n",
    "    args['mu_'] = mu_\n",
    "    args['sigma_'] = sigma_\n",
    "    args['recombination'] = recombination\n",
    "    run_id = f'ES_P100_M{mu_}_L{lambda_}_S{sigma_}_T0.2_C3_REC{recombination}_IS'\n",
    "    args['run_id'] = run_id\n",
    "\n",
    "    # run the experiment\n",
    "    init_ipynb(NB, args, save_to=DIRS['csv_exp'])\n",
    "    progress(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path: str, best_so_far: bool = False):\n",
    "    \"\"\"\n",
    "    Load all csv files in data_path and return a dictionary with the data.\n",
    "    db[run_id] = np.array with shape (repetitions, budget)\n",
    "    If best_so_far is True, the array will only contain the best value so far for each time step.\n",
    "    \"\"\"\n",
    "    db = {}\n",
    "    files = os.listdir(data_path)\n",
    "    # sort by moment of creation to ensure correct order wrt run_id\n",
    "    files.sort(key=lambda x: os.path.getmtime(data_path + os.sep + x))\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(data_path + os.sep + file, index_col=0)\n",
    "            if best_so_far:\n",
    "                db[file[:-4]] = df.cummax().values\n",
    "            else:\n",
    "                db[file[:-4]] = df.values\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_settings_from_run_id(run_id: str, params: list[str]) -> dict[str, str]:\n",
    "    \"\"\"Small helper function to reduce complexity in plot function.\"\"\"\n",
    "    param_replacements = {\n",
    "        'M': '$\\mu$',\n",
    "        'L': '$\\lambda$',\n",
    "        'S': '$\\sigma$',\n",
    "        'T': '$\\tau$',\n",
    "        'C': 'chunksize',\n",
    "        'SEL': 'sel',\n",
    "        'REC': 'rec',\n",
    "        'MUT': 'mut',\n",
    "    }\n",
    "    settings = {}\n",
    "    for setting in run_id.split('_'):\n",
    "        for param in params:\n",
    "            if param == setting[:len(param)]:\n",
    "                # check for special case (MUT also matches M)\n",
    "                if param == 'M' and setting[:3] == 'MUT':\n",
    "                    continue\n",
    "                param_r = param_replacements[param]\n",
    "                settings[param_r] = setting.replace(param, '')\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    db: dict[str, np.ndarray],\n",
    "    title: str,\n",
    "    params: list[str] = None,\n",
    "    best_so_far: bool = False,\n",
    "    custom_labels: dict[str, str] = None,\n",
    "    ) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plots the learning curves for all experiments in db.\n",
    "    db is a dict that maps the run_id to the data (see get_data).\n",
    "    The columns in this data represent independent repetitions, and their rows represent best fitness found per generation,\n",
    "    or the best fitness found so far if best_so_far is True.\n",
    "    The run_id will determine their labels in the legend, unless custom_labels is provided.\n",
    "    The data will be shown as thin lines for each repetition, and the mean will be shown as a thick line.\n",
    "    The standard deviation will be shown as a shaded area.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, (run_id, data) in enumerate(db.items()):\n",
    "        # create the label\n",
    "        if custom_labels is not None:\n",
    "            label = custom_labels[run_id]\n",
    "        else:\n",
    "            settings = extract_settings_from_run_id(run_id, params)\n",
    "            label = ', '.join([f'{param}={setting}' for param, setting in settings.items()])\n",
    "        # raw data from each repetition\n",
    "        for j in range(data.shape[1]):\n",
    "            ax.plot(data[:, j], color=f'C{i}', alpha=0.2, linewidth=0.5)\n",
    "        # standard deviation\n",
    "        ax.fill_between(\n",
    "            np.arange(data.shape[0]), data.mean(axis=1) - data.std(axis=1),\n",
    "            data.mean(axis=1) + data.std(axis=1),\n",
    "            color = f'C{i}',\n",
    "            alpha = 0.1\n",
    "        )\n",
    "        # mean\n",
    "        ax.plot(\n",
    "            data.mean(axis=1),\n",
    "            color = f'C{i}',\n",
    "            alpha = 0.8,\n",
    "            linewidth = 2,\n",
    "            label = label\n",
    "        )\n",
    "    # reference line for f_opt\n",
    "    ax.axhline(0.950554, color='gray', linestyle='--', alpha = 1, linewidth=1)\n",
    "    # add text in upper left corner\n",
    "    ax.text(0.05, 0.95, '$f^*$', transform=ax.transAxes, fontsize=14, verticalalignment='top', color='gray')\n",
    "    \n",
    "    # finishing touches\n",
    "    ax.set_xlim(-1, 50)\n",
    "    ax.set_xticks([0] + list(range(9, 50, 10)), [1] + list(range(10, 51, 10)))\n",
    "    ax.set_xlabel('generation', fontsize=12)\n",
    "    ax.set_ylabel(r'$f^*_{\\mathrm{found}}$', fontsize=12)\n",
    "    ax.legend(fontsize=12, loc='lower right')\n",
    "    ax.set_title(title, weight='bold', fontsize=16)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GA_1 = get_data(DIRS['csv'] + 'GA_fin')\n",
    "fig_GA_1 = plot_learning_curve(\n",
    "    db = data_GA_1,\n",
    "    title = r'Best $\\mathbf{f}$ found per generation (GA)',\n",
    "    params = ['M', 'L', 'SEL', 'MUT']\n",
    ")\n",
    "fig_GA_1.savefig(DIRS['plots'] + 'GA_f1.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GA_2 = get_data(DIRS['csv'] + 'GA_fin', best_so_far=True)\n",
    "fig_GA_2 = plot_learning_curve(\n",
    "    db = data_GA_2,\n",
    "    title = 'Best $\\mathbf{f}$ found so far (GA)',\n",
    "    params = ['M', 'L', 'SEL', 'MUT'],\n",
    "    best_so_far = True\n",
    ")\n",
    "fig_GA_2.savefig(DIRS['plots'] + 'GA_f2.png', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ES plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ES = get_data(DIRS['csv'] + 'ES_fin')\n",
    "fig_ES = plot_learning_curve(\n",
    "    db = data_ES,\n",
    "    title = r'Best $\\mathbf{f}$ found per generation (ES)',\n",
    "    params = ['M', 'L', 'S', 'REC'],\n",
    "    best_so_far = False\n",
    ")\n",
    "fig_ES.savefig(DIRS['plots'] + 'ES_f.png', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best GA run is M=20 L=80, SEL=ts, MUT=u-0.04\n",
    "# best EA run is M=20 L=80, S=0.1, REC=dg\n",
    "\n",
    "GA_id = 'P100_M20_L80_SELts_RECu_MUTu-0.04'\n",
    "ES_id = 'P100_M20_L80_S0.1_T0.2_C3_RECdg_IS'\n",
    "\n",
    "GA_data = pd.read_csv(DIRS['csv'] + 'GA_fin' + os.sep + f'GA_{GA_id}.csv', index_col=0).cummax().values\n",
    "ES_data = pd.read_csv(DIRS['csv'] + 'ES_fin' + os.sep + f'ES_{ES_id}.csv', index_col=0).values\n",
    "\n",
    "GA_label = r'GA | $\\mu=20$, $\\lambda=80$, sel=ts, mut=u-0.04'\n",
    "ES_label = r'ES | $\\mu=20$, $\\lambda=80$, $\\sigma=0.1$, rec=dg'\n",
    "\n",
    "comp_db = {'GA_id': GA_data, 'ES_id': ES_data}\n",
    "comp_labels = {'GA_id': GA_label, 'ES_id': ES_label}\n",
    "\n",
    "fig_comp = plot_learning_curve(\n",
    "    db = comp_db,\n",
    "    title = 'Comparison of GA and ES',\n",
    "    params = None,\n",
    "    best_so_far = True,\n",
    "    custom_labels = comp_labels\n",
    ")\n",
    "fig_comp.savefig(DIRS['plots'] + 'GA_vs_ES.png', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba309399f570c57919de3bfb36c195c6481f6cdea1861c2eb2b107e7cf184e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
