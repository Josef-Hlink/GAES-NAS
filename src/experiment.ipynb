{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nasbench.api import NASBench\n",
    "\n",
    "from main import init_ipynb, main\n",
    "from utils import get_directories, ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NASBench('../data/nasbench_only108.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = get_directories(os.path.join(os.path.abspath(''), 'experiment.ipynb'))\n",
    "exp_id = 'GA_exp2'\n",
    "DIRS['csv_exp'] = DIRS['csv'] + exp_id + os.sep\n",
    "if not os.path.exists(DIRS['csv_exp']):\n",
    "    os.mkdir(DIRS['csv_exp'])\n",
    "\n",
    "for n, p in DIRS.items():\n",
    "    print(f'{n}: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_GA = dict(\n",
    "    optimizer = 'GA',\n",
    "    population_size = 100,\n",
    "    mu_ = 40,\n",
    "    lambda_ = 60,\n",
    "    budget = 5000,\n",
    "    recombination = 'kp',\n",
    "    selection = 'rw',\n",
    "    mutation = 'uniform',\n",
    "    xp = 1,\n",
    "    mut_r = None,\n",
    "    mut_b = None,\n",
    "    run_id = None,\n",
    "    verbose = 0,\n",
    "    seed = 42,\n",
    "    repetitions = 20,\n",
    "    log = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = ['rw', 'ts', 'rk', 'su']\n",
    "mutations = [('u', 0.001), ('u', 0.005), ('u', 0.1), ('b', 1), ('b', 2), ('b', 3)]\n",
    "recombinations = [('kp', 1), ('kp', 2), ('kp', 3), ('u', None)]\n",
    "pop_divisions = [(100, 40, 60), (100, 40, 100), (100, 20, 80), (100, 20, 100)]\n",
    "pop_divisions += [(40, 20, 20), (40, 20, 40), (40, 10, 30), (40, 10, 40)]\n",
    "\n",
    "# create a list of all combinations of the above parameters\n",
    "combinations = list(product(selections, mutations, recombinations, pop_divisions))\n",
    "n_combs = len(combinations)\n",
    "progress = ProgressBar(n_combs, exp_id)\n",
    "\n",
    "for i, (sel, mut, rec, (ps, mu, lm)) in enumerate(combinations):\n",
    "    args = default_args_GA.copy()\n",
    "    args['selection'] = sel\n",
    "    args['mutation'] = mut[0]\n",
    "    if mut[0] == 'u':\n",
    "        args['mut_r'] = mut[1]\n",
    "    else:\n",
    "        args['mut_b'] = mut[1]\n",
    "    args['recombination'] = rec[0]\n",
    "    args['xp'] = rec[1]\n",
    "    args['population_size'] = ps\n",
    "    args['mu_'] = mu\n",
    "    args['lambda_'] = lm\n",
    "    run_id = f'GA_{ps}_{mu}_{lm}_{sel}_{mut[0]}({mut[1]})_{rec[0]}({rec[1]})'.replace('(None)', '')\n",
    "    args['run_id'] = run_id\n",
    "\n",
    "    init_ipynb(NB, args)\n",
    "    main(save_to=DIRS['csv_exp'])\n",
    "\n",
    "    progress(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GA = pd.DataFrame(columns=['max_avg_value', 'pop_size', 'mu', 'lambda', 'selection', 'mutation', 'recombination'])\n",
    "df_GA.index.name = 'run_id'\n",
    "\n",
    "for file in os.listdir(DIRS['csv_exp']):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    df_ = pd.read_csv(os.path.join(DIRS['csv_exp'], file), index_col=0)\n",
    "    max_val = df_.mean(axis=1).iloc[-1]\n",
    "    run_id = file[3:-4]  # trim 'GA_' and '.csv'\n",
    "    ps, mu, lm, sel, mut, rec = run_id.split('_')\n",
    "    df_GA.loc[run_id] = [max_val, ps, mu, lm, sel, mut, rec]\n",
    "\n",
    "# sort by highest value\n",
    "df_GA = df_GA.sort_values(by='max_avg_value', ascending=False)\n",
    "\n",
    "# save to csv with same name as dir where all individual csv files are stored\n",
    "df_GA.to_csv(os.path.join(DIRS['csv'], f'{exp_id}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elitism(df: pd.DataFrame, title: str) -> plt.Figure:\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    df = df.copy()\n",
    "    \n",
    "    # observations\n",
    "    df['color'] = 'tab:blue' # μ,λ\n",
    "    df.loc[df['pop_size'] == df['lambda'], 'color'] = 'tab:orange'  # μ+λ (elitism)\n",
    "    ax.scatter(df.index, list(reversed(list(df['max_avg_value']))), c=df['color'], marker='|', s=50, alpha=1)\n",
    "    ax.set_ylabel('Validation accuracy')\n",
    "    ax.set_xlabel('Frequency / Ranking')\n",
    "    ax.set_xticks([], [])\n",
    "    ax.set_title(title, weight='bold')\n",
    "    \n",
    "    # distribution\n",
    "    twax = ax.twiny()\n",
    "    df_comma = df[df['color'] == 'tab:blue']\n",
    "    df_plus = df[df['color'] == 'tab:orange']\n",
    "    df_comma.hist(column='max_avg_value', ax=twax, color='tab:blue', alpha=0.5, bins=100, orientation='horizontal', label='$\\mu,\\lambda$')\n",
    "    df_plus.hist(column='max_avg_value', ax=twax, color='tab:orange', alpha=0.5, bins=100, orientation='horizontal', label='$\\mu+\\lambda$')\n",
    "    twax.grid(False)\n",
    "    twax.set_ylabel('')\n",
    "    twax.set_xticks([], [])\n",
    "    twax.set_title('')\n",
    "    twax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_elitism_GA = plot_elitism(df_GA, title='$\\mathbf{\\mu,\\lambda}$ vs $\\mathbf{\\mu+\\lambda}$ in GA')\n",
    "fig_elitism_GA.savefig(DIRS['plots'] + f'{exp_id}_elitism.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'ES_exp2'\n",
    "DIRS['csv_exp'] = DIRS['csv'] + exp_id + os.sep\n",
    "if not os.path.exists(DIRS['csv_exp']):\n",
    "    os.mkdir(DIRS['csv_exp'])\n",
    "\n",
    "for n, p in DIRS.items():\n",
    "    print(f'{n}: {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_ES = dict(\n",
    "    optimizer = 'ES',\n",
    "    population_size = 100,\n",
    "    mu_ = 40,\n",
    "    lambda_ = 60,\n",
    "    budget = 5000,\n",
    "    recombination = 'd',\n",
    "    tau_ = 0.1,\n",
    "    sigma_ = 0.01,\n",
    "    chunk_size = 3,\n",
    "    individual_sigmas = False,\n",
    "    run_id = None,\n",
    "    verbose = 0,\n",
    "    seed = 42,\n",
    "    repetitions = 20,\n",
    "    log = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recombinations = ['d', 'i', 'dg', 'ig']\n",
    "taus = [0.1, 0.2, 0.5, 0.99]\n",
    "sigmas = [0.01, 0.1, 0.5]\n",
    "chunk_sizes = [3, 7]\n",
    "individual_sigmas = [True, False]\n",
    "pop_divisions = [(100, 40, 60), (100, 40, 100), (100, 20, 80), (100, 20, 100)]\n",
    "pop_divisions += [(40, 20, 20), (40, 20, 40), (40, 10, 30), (40, 10, 40)]\n",
    "\n",
    "combinations = list(product(recombinations, taus, sigmas, chunk_sizes, individual_sigmas, pop_divisions))\n",
    "n_combs = len(combinations)\n",
    "progress = ProgressBar(n_combs, exp_id)\n",
    "\n",
    "for i, (rec, tau, sig, chsz, isig, (ps, mu, lm)) in enumerate(combinations):\n",
    "    args = default_args_ES.copy()\n",
    "    args['recombination'] = rec\n",
    "    args['tau_'] = tau\n",
    "    args['sigma_'] = sig\n",
    "    args['chunk_size'] = chsz\n",
    "    args['individual_sigmas'] = isig\n",
    "    args['population_size'] = ps\n",
    "    args['mu_'] = mu\n",
    "    args['lambda_'] = lm\n",
    "    run_id = f'ES_{ps}_{mu}_{lm}_{rec}_{sig}_{tau}_{chsz}_{isig}'\n",
    "    args['run_id'] = run_id\n",
    "\n",
    "    init_ipynb(NB, args)\n",
    "    main(save_to=DIRS['csv_exp'])\n",
    "\n",
    "    progress(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ES = pd.DataFrame(columns=['max_avg_value', 'pop_size', 'mu', 'lambda', 'recombination', 'sigma', 'tau', 'chunk_size', 'individual_sigmas'])\n",
    "df_ES.index.name = 'run_id'\n",
    "\n",
    "for file in os.listdir(DIRS['csv_exp']):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    df_ = pd.read_csv(os.path.join(DIRS['csv_exp'], file), index_col=0)\n",
    "    max_val = df_.mean(axis=1).iloc[-1]\n",
    "    run_id = file[3:-4]  # trim 'ES_' and '.csv'\n",
    "    ps, mu, lm, rec, sig, tau, chsz, isig = run_id.split('_')\n",
    "    df_ES.loc[run_id] = [max_val, ps, mu, lm, rec, sig, tau, chsz, isig]\n",
    "\n",
    "# sort by highest value\n",
    "df_ES = df_ES.sort_values(by='max_avg_value', ascending=False)\n",
    "\n",
    "# save to csv with same name as dir where all individual csv files are stored\n",
    "df_ES.to_csv(os.path.join(DIRS['csv'], f'{exp_id}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ES = pd.read_csv(DIRS['csv'] + f'{exp_id}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_split(dfs: list[pd.DataFrame], headers: list[str], title: str) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Takes number of (min 2, max 4) dataframes and plots the \"raw\" results along with a histogram in separate subplots.\n",
    "    2 & 3 dfs will be shown in one row, 4 will result in a 2x2 grid.\n",
    "    Headers are used as titles for the subplots, so they should be in the same order as the dataframes.\n",
    "    The title is used for the whole figure.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(dfs) > 1 and len(dfs) < 5, \"Please only give 2, 3 or 4 dataframes\"\n",
    "    assert len(dfs) == len(headers), \"Please give as many headers as dataframes\"\n",
    "    ndfs = len(dfs)\n",
    "\n",
    "    if ndfs != 4:\n",
    "        fig, axes = plt.subplots(1, ndfs, figsize=(5*ndfs, 5), sharey=True)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        # spread axes so we can loop over them\n",
    "        axes = list(axes[0]) + list(axes[1])\n",
    "    \n",
    "    # will be used to set bounds for the histograms, as y-axis is shared\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "    bounds = (full_df.max_avg_value.min(), full_df.max_avg_value.max())\n",
    "    # small delta to avoid clipping\n",
    "    delta = (bounds[1] - bounds[0]) * 0.01\n",
    "    bounds = (bounds[0] - delta, bounds[1] + delta)\n",
    "\n",
    "    rev = lambda s: list(reversed(list(s)))\n",
    "    for i, (df, ax) in enumerate(zip(dfs, axes)):\n",
    "        # observations\n",
    "        ax.scatter(df.index, rev(df.max_avg_value), c=f'C{i}', marker='|', s=10)\n",
    "        ax.set_title(headers[i])\n",
    "        if i == 0: ax.set_ylabel('validation accuracy')\n",
    "        ax.set_xlabel('frequency / ranking')\n",
    "        ax.set_xticks([], [])\n",
    "        ax.set_ylim(bounds)\n",
    "    \n",
    "        # histogram\n",
    "        ax2 = ax.twinx()\n",
    "        bins = np.arange(bounds[0], bounds[1], (bounds[1]-bounds[0])/50)\n",
    "        ax2.hist(df.max_avg_value, bins=bins, orientation='horizontal', color=f'C{i}', alpha=0.5)\n",
    "        ax2.grid(False)\n",
    "        ax2.set_yticks([], [])\n",
    "        ax2.set_xticks([], [])\n",
    "        ax2.set_title('')\n",
    "        ax2.set_ylim(bounds)\n",
    "\n",
    "    fig.suptitle(title, fontsize=16, weight='bold')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comma = df_ES[df_ES['lambda'] == df_ES['pop_size']]\n",
    "df_plus = df_ES[df_ES['lambda'] != df_ES['pop_size']]\n",
    "fig = plot_split([df_comma, df_plus], ['\\u03bb,\\u03bc', '\\u03bb+\\u03bc'], '\\u03bb,\\u03bc vs. \\u03bb+\\u03bc in ES')\n",
    "fig.savefig(DIRS['plots'] + f'elitism_ES1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = df_plus.max_avg_value.min()\n",
    "# clip comma to lb\n",
    "df_comma = df_comma[df_comma.max_avg_value > lb]\n",
    "# plot again\n",
    "fig = plot_split([df_comma, df_plus], ['\\u03bb,\\u03bc', '\\u03bb+\\u03bc'], '\\u03bb,\\u03bc vs. \\u03bb+\\u03bc in ES (clipped)')\n",
    "fig.savefig(DIRS['plots'] + f'elitism_ES2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we gather that $\\mu,\\lambda$ is not reliable to use in combination with ES for this particular problem.\n",
    "From this point, we will only use the $\\mu+\\lambda$-ES results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_plus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population size comparison\n",
    "df_100 = df[df['pop_size'] == 100]\n",
    "df_40 = df[df['pop_size'] == 40]\n",
    "\n",
    "fig = plot_split([df_100, df_40], ['100', '40'], 'Population size in ES')\n",
    "fig.savefig(DIRS['plots'] + 'popsize_ES.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba309399f570c57919de3bfb36c195c6481f6cdea1861c2eb2b107e7cf184e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
